train_Precision: 0.00000000, train_Loss: 3.92654610
train_Precision: 8.33333333, train_Loss: 4.50354719
train_Precision: 8.33333333, train_Loss: 5.11407232
train_Precision: 0.00000000, train_Loss: 6.05166960
train_Precision: 0.00000000, train_Loss: 5.74916267
train_Precision: 0.00000000, train_Loss: 4.94051981
train_Precision: 0.00000000, train_Loss: 7.21774530
train_Precision: 0.00000000, train_Loss: 9.57157230
train_Precision: 0.00000000, train_Loss: 7.18478918
train_Precision: 8.33333333, train_Loss: 8.25786877
train_Precision: 8.33333333, train_Loss: 6.03119469
train_Precision: 0.00000000, train_Loss: 6.37297392
train_Precision: 0.00000000, train_Loss: 5.87842035
train_Precision: 0.00000000, train_Loss: 7.92520666
train_Precision: 0.00000000, train_Loss: 11.62996674
train_Precision: 8.33333333, train_Loss: 5.62579536
train_Precision: 0.00000000, train_Loss: 7.36748075
train_Precision: 0.00000000, train_Loss: 9.39244556
train_Precision: 0.00000000, train_Loss: 6.57948351
train_Precision: 8.33333333, train_Loss: 4.53936148
train_Precision: 0.00000000, train_Loss: 7.33469820
train_Precision: 0.00000000, train_Loss: 6.87427282
train_Precision: 0.00000000, train_Loss: 5.89097023
train_Precision: 0.00000000, train_Loss: 3.80142713
train_Precision: 0.00000000, train_Loss: 6.35612249
train_Precision: 0.00000000, train_Loss: 4.79839087
train_Precision: 8.33333333, train_Loss: 9.92949963
train_Precision: 0.00000000, train_Loss: 7.29949141
train_Precision: 0.00000000, train_Loss: 5.50090933
train_Precision: 0.00000000, train_Loss: 4.37352133
train_Precision: 0.00000000, train_Loss: 3.82198334
train_Precision: 0.00000000, train_Loss: 4.60680294
train_Precision: 0.00000000, train_Loss: 4.63740301
train_Precision: 8.33333333, train_Loss: 4.33266830
train_Precision: 0.00000000, train_Loss: 5.19463396
train_Precision: 0.00000000, train_Loss: 6.48565102
train_Precision: 0.00000000, train_Loss: 5.60159159
train_Precision: 8.33333333, train_Loss: 4.22486877
train_Precision: 0.00000000, train_Loss: 5.34097099
train_Precision: 0.00000000, train_Loss: 6.16267776
train_Precision: 8.33333333, train_Loss: 4.78291273
train_Precision: 0.00000000, train_Loss: 3.51867270
train_Precision: 8.33333333, train_Loss: 4.63209772
train_Precision: 8.33333333, train_Loss: 4.66792345
train_Precision: 0.00000000, train_Loss: 4.66580772
train_Precision: 8.33333333, train_Loss: 4.10766459
train_Precision: 0.00000000, train_Loss: 4.17152786
train_Precision: 0.00000000, train_Loss: 4.34267092
train_Precision: 8.33333333, train_Loss: 4.27597237
train_Precision: 0.00000000, train_Loss: 4.70971870
train_Precision: 0.00000000, train_Loss: 4.70019102
train_Precision: 8.33333333, train_Loss: 3.42208076
train_Precision: 0.00000000, train_Loss: 3.73605919
train_Precision: 8.33333333, train_Loss: 4.51914644
train_Precision: 8.33333333, train_Loss: 5.44894409
train_Precision: 0.00000000, train_Loss: 4.52122068
train_Precision: 0.00000000, train_Loss: 4.85549307
train_Precision: 0.00000000, train_Loss: 4.31572199
train_Precision: 8.33333333, train_Loss: 3.76930904
train_Precision: 0.00000000, train_Loss: 4.82198954
train_Precision: 0.00000000, train_Loss: 3.82452774
train_Precision: 16.66666667, train_Loss: 4.14952707
train_Precision: 0.00000000, train_Loss: 4.23751736
train_Precision: 0.00000000, train_Loss: 4.66509104
train_Precision: 0.00000000, train_Loss: 4.27495623
train_Precision: 0.00000000, train_Loss: 4.71969175
train_Precision: 0.00000000, train_Loss: 4.64665413
train_Precision: 0.00000000, train_Loss: 4.42310190
train_Precision: 0.00000000, train_Loss: 3.79160428
train_Precision: 0.00000000, train_Loss: 4.16149044
train_Precision: 8.33333333, train_Loss: 4.35172415
train_Precision: 0.00000000, train_Loss: 4.62337065
train_Precision: 0.00000000, train_Loss: 4.29202986
train_Precision: 0.00000000, train_Loss: 4.22374201
train_Precision: 0.00000000, train_Loss: 4.03579187
train_Precision: 0.00000000, train_Loss: 4.29222918
train_Precision: 0.00000000, train_Loss: 4.01215506
train_Precision: 8.33333333, train_Loss: 4.45352507
train_Precision: 0.00000000, train_Loss: 3.66820812
train_Precision: 0.00000000, train_Loss: 4.02210283
train_Precision: 0.00000000, train_Loss: 4.03153658
train_Precision: 0.00000000, train_Loss: 3.90189624
train_Precision: 0.00000000, train_Loss: 4.19283915
train_Precision: 0.00000000, train_Loss: 3.92761016
train_Precision: 8.33333333, train_Loss: 3.69458961
train_Precision: 0.00000000, train_Loss: 4.09529972
train_Precision: 0.00000000, train_Loss: 4.41489649
train_Precision: 0.00000000, train_Loss: 4.58560610
train_Precision: 0.00000000, train_Loss: 4.01094294
train_Precision: 8.33333333, train_Loss: 3.81134200
train_Precision: 0.00000000, train_Loss: 3.70044327
train_Precision: 8.33333333, train_Loss: 3.72759748
train_Precision: 8.33333333, train_Loss: 4.06334543
train_Precision: 0.00000000, train_Loss: 4.06693554
train_Precision: 0.00000000, train_Loss: 4.10446072
train_Precision: 0.00000000, train_Loss: 4.22500324
train_Precision: 8.33333333, train_Loss: 3.69837165
train_Precision: 0.00000000, train_Loss: 4.28262663
train_Precision: 8.33333333, train_Loss: 3.52558136
train_Precision: 8.33333333, train_Loss: 3.54017949
train_Precision: 16.66666667, train_Loss: 3.74342465
train_Precision: 8.33333333, train_Loss: 3.72405529
train_Precision: 8.33333333, train_Loss: 3.78171897
train_Precision: 0.00000000, train_Loss: 3.70169425
train_Precision: 0.00000000, train_Loss: 3.94048381
train_Precision: 8.33333333, train_Loss: 3.95373654
train_Precision: 8.33333333, train_Loss: 3.66536403
train_Precision: 0.00000000, train_Loss: 4.14558935
train_Precision: 0.00000000, train_Loss: 3.62484741
train_Precision: 0.00000000, train_Loss: 3.84442139
train_Precision: 8.33333333, train_Loss: 3.36038423
train_Precision: 16.66666667, train_Loss: 3.48860478
train_Precision: 0.00000000, train_Loss: 4.06789923
train_Precision: 0.00000000, train_Loss: 4.35809565
train_Precision: 0.00000000, train_Loss: 4.13861704
train_Precision: 16.66666667, train_Loss: 3.36860442
train_Precision: 8.33333333, train_Loss: 3.90698814
train_Precision: 0.00000000, train_Loss: 3.49311352
train_Precision: 0.00000000, train_Loss: 3.73807120
train_Precision: 8.33333333, train_Loss: 3.48477530
train_Precision: 8.33333333, train_Loss: 3.89227581
train_Precision: 0.00000000, train_Loss: 3.99255443
train_Precision: 8.33333333, train_Loss: 3.89081120
train_Precision: 0.00000000, train_Loss: 3.66869640
train_Precision: 8.33333333, train_Loss: 3.46510911
train_Precision: 0.00000000, train_Loss: 3.83134270
train_Precision: 8.33333333, train_Loss: 3.72479248
train_Precision: 0.00000000, train_Loss: 3.74988437
train_Precision: 0.00000000, train_Loss: 4.04794216
train_Precision: 8.33333333, train_Loss: 4.07418585
train_Precision: 8.33333333, train_Loss: 3.42875600
train_Precision: 8.33333333, train_Loss: 3.61602998
train_Precision: 0.00000000, train_Loss: 3.90063858
train_Precision: 0.00000000, train_Loss: 3.88785863
train_Precision: 0.00000000, train_Loss: 4.01924896
train_Precision: 0.00000000, train_Loss: 3.84906578
train_Precision: 16.66666667, train_Loss: 3.54726601
train_Precision: 8.33333333, train_Loss: 3.43590426
train_Precision: 16.66666667, train_Loss: 3.77664948
train_Precision: 16.66666667, train_Loss: 3.79937339
train_Precision: 0.00000000, train_Loss: 3.75126624
train_Precision: 8.33333333, train_Loss: 3.98681808
train_Precision: 0.00000000, train_Loss: 4.00204325
train_Precision: 0.00000000, train_Loss: 3.70893455
train_Precision: 0.00000000, train_Loss: 3.81745696
train_Precision: 0.00000000, train_Loss: 3.82356000
train_Precision: 0.00000000, train_Loss: 3.83746338
train_Precision: 0.00000000, train_Loss: 3.68035245
train_Precision: 0.00000000, train_Loss: 3.67611289
train_Precision: 0.00000000, train_Loss: 3.44621968
train_Precision: 8.33333333, train_Loss: 3.28810024
train_Precision: 0.00000000, train_Loss: 3.73970318
train_Precision: 0.00000000, train_Loss: 4.15281439
train_Precision: 16.66666667, train_Loss: 3.68161035
train_Precision: 0.00000000, train_Loss: 4.14977407
train_Precision: 8.33333333, train_Loss: 3.79210186
train_Precision: 16.66666667, train_Loss: 3.37870145
train_Precision: 0.00000000, train_Loss: 3.77148557
train_Precision: 0.00000000, train_Loss: 3.69284439
train_Precision: 8.33333333, train_Loss: 3.84760952
train_Precision: 0.00000000, train_Loss: 3.82071567
train_Precision: 16.66666667, train_Loss: 3.53562665
train_Precision: 0.00000000, train_Loss: 3.89863014
train_Precision: 16.66666667, train_Loss: 3.50490069
train_Precision: 0.00000000, train_Loss: 3.89320922
train_Precision: 0.00000000, train_Loss: 3.97150588
train_Precision: 0.00000000, train_Loss: 3.74750590
train_Precision: 0.00000000, train_Loss: 3.80704570
train_Precision: 8.33333333, train_Loss: 3.65537143
train_Precision: 8.33333333, train_Loss: 3.89825749
train_Precision: 0.00000000, train_Loss: 3.93102551
train_Precision: 0.00000000, train_Loss: 3.75496650
train_Precision: 8.33333333, train_Loss: 3.37559247
train_Precision: 8.33333333, train_Loss: 3.72070718
train_Precision: 0.00000000, train_Loss: 3.82067394
train_Precision: 8.33333333, train_Loss: 3.49482179
train_Precision: 8.33333333, train_Loss: 3.53666520
train_Precision: 16.66666667, train_Loss: 3.58526874
train_Precision: 8.33333333, train_Loss: 3.80468845
train_Precision: 8.33333333, train_Loss: 3.47368813
train_Precision: 8.33333333, train_Loss: 3.61895657
train_Precision: 0.00000000, train_Loss: 3.87542367
train_Precision: 0.00000000, train_Loss: 3.97481608
train_Precision: 0.00000000, train_Loss: 3.50380611
train_Precision: 0.00000000, train_Loss: 3.80868030
train_Precision: 0.00000000, train_Loss: 3.78298211
train_Precision: 16.66666667, train_Loss: 3.60714316
train_Precision: 0.00000000, train_Loss: 3.57332611
train_Precision: 0.00000000, train_Loss: 3.56034923
train_Precision: 0.00000000, train_Loss: 3.78671551
train_Precision: 0.00000000, train_Loss: 3.90140939
train_Precision: 0.00000000, train_Loss: 3.79778576
train_Precision: 8.33333333, train_Loss: 3.35128903
train_Precision: 8.33333333, train_Loss: 3.41796327
train_Precision: 8.33333333, train_Loss: 3.70923448
train_Precision: 0.00000000, train_Loss: 4.06682348
train_Precision: 0.00000000, train_Loss: 4.02048016
train_Precision: 0.00000000, train_Loss: 4.18094444
train_Precision: 0.00000000, train_Loss: 4.01607466
train_Precision: 0.00000000, train_Loss: 3.69831944
train_Precision: 0.00000000, train_Loss: 3.89439511
train_Precision: 0.00000000, train_Loss: 3.97436881
train_Precision: 0.00000000, train_Loss: 3.81684518
train_Precision: 16.66666667, train_Loss: 3.57123971
train_Precision: 16.66666667, train_Loss: 3.66429138
train_Precision: 0.00000000, train_Loss: 3.82417989
train_Precision: 0.00000000, train_Loss: 3.54628849
train_Precision: 0.00000000, train_Loss: 3.65071297
train_Precision: 16.66666667, train_Loss: 3.65085006
train_Precision: 0.00000000, train_Loss: 3.87658191
train_Precision: 8.33333333, train_Loss: 3.64287496
train_Precision: 8.33333333, train_Loss: 3.47935414
train_Precision: 25.00000000, train_Loss: 3.49692607
train_Precision: 0.00000000, train_Loss: 3.87010407
train_Precision: 0.00000000, train_Loss: 3.78407860
train_Precision: 8.33333333, train_Loss: 3.67027640
train_Precision: 0.00000000, train_Loss: 3.75751400
train_Precision: 16.66666667, train_Loss: 3.75733590
train_Precision: 0.00000000, train_Loss: 3.77823329
train_Precision: 8.33333333, train_Loss: 3.93039632
train_Precision: 0.00000000, train_Loss: 3.88503718
train_Precision: 0.00000000, train_Loss: 3.80903077
train_Precision: 8.33333333, train_Loss: 3.57659721
train_Precision: 0.00000000, train_Loss: 3.62623596
train_Precision: 8.33333333, train_Loss: 3.64734674
train_Precision: 0.00000000, train_Loss: 3.52891827
train_Precision: 0.00000000, train_Loss: 3.78425670
train_Precision: 0.00000000, train_Loss: 3.83189845
train_Precision: 0.00000000, train_Loss: 3.82513237
train_Precision: 8.33333333, train_Loss: 3.69813466
train_Precision: 8.33333333, train_Loss: 3.81715202
train_Precision: 16.66666667, train_Loss: 3.23562050
train_Precision: 8.33333333, train_Loss: 3.69668937
train_Precision: 8.33333333, train_Loss: 3.55208683
train_Precision: 0.00000000, train_Loss: 4.02513742
train_Precision: 8.33333333, train_Loss: 3.82999802
train_Precision: 0.00000000, train_Loss: 4.07227087
train_Precision: 0.00000000, train_Loss: 3.78360724
train_Precision: 0.00000000, train_Loss: 3.73421788
train_Precision: 0.00000000, train_Loss: 3.72082829
train_Precision: 0.00000000, train_Loss: 3.78632927
train_Precision: 8.33333333, train_Loss: 3.76076341
train_Precision: 0.00000000, train_Loss: 3.96393847
train_Precision: 8.33333333, train_Loss: 3.73984408
train_Precision: 8.33333333, train_Loss: 3.77401948
train_Precision: 0.00000000, train_Loss: 3.68226814
train_Precision: 0.00000000, train_Loss: 3.51712155
train_Precision: 0.00000000, train_Loss: 4.02630186
train_Precision: 8.33333333, train_Loss: 3.50490451
train_Precision: 8.33333333, train_Loss: 3.67580318
train_Precision: 0.00000000, train_Loss: 3.66351128
train_Precision: 0.00000000, train_Loss: 3.77535462
train_Precision: 0.00000000, train_Loss: 3.74742007
train_Precision: 0.00000000, train_Loss: 3.57120323
train_Precision: 8.33333333, train_Loss: 3.61407280
train_Precision: 25.00000000, train_Loss: 3.46629643
train_Precision: 0.00000000, train_Loss: 4.00382710
train_Precision: 0.00000000, train_Loss: 3.69720912
train_Precision: 0.00000000, train_Loss: 4.14031982
train_Precision: 0.00000000, train_Loss: 4.09406662
train_Precision: 0.00000000, train_Loss: 3.82152438
train_Precision: 0.00000000, train_Loss: 3.70723915
train_Precision: 0.00000000, train_Loss: 3.99370313
train_Precision: 8.33333333, train_Loss: 3.45827699
train_Precision: 0.00000000, train_Loss: 3.96495748
train_Precision: 0.00000000, train_Loss: 3.99766541
train_Precision: 0.00000000, train_Loss: 3.72122407
train_Precision: 16.66666667, train_Loss: 3.56088901
train_Precision: 0.00000000, train_Loss: 3.64138603
train_Precision: 0.00000000, train_Loss: 4.02620125
train_Precision: 0.00000000, train_Loss: 3.65694237
train_Precision: 8.33333333, train_Loss: 3.62779808
train_Precision: 0.00000000, train_Loss: 3.66805577
train_Precision: 0.00000000, train_Loss: 3.84315300
train_Precision: 0.00000000, train_Loss: 3.92703247
train_Precision: 0.00000000, train_Loss: 3.81899929
train_Precision: 0.00000000, train_Loss: 3.75488091
train_Precision: 0.00000000, train_Loss: 3.83677125
train_Precision: 0.00000000, train_Loss: 3.67953777
train_Precision: 8.33333333, train_Loss: 3.68073583
train_Precision: 16.66666667, train_Loss: 3.57453632
train_Precision: 8.33333333, train_Loss: 3.56730652
train_Precision: 16.66666667, train_Loss: 3.70025659
train_Precision: 8.33333333, train_Loss: 3.89695096
train_Precision: 0.00000000, train_Loss: 3.80940127
train_Precision: 0.00000000, train_Loss: 3.78328395
train_Precision: 0.00000000, train_Loss: 3.78020167
train_Precision: 8.33333333, train_Loss: 3.64891887
train_Precision: 0.00000000, train_Loss: 3.97999954
train_Precision: 0.00000000, train_Loss: 4.04748917
train_Precision: 8.33333333, train_Loss: 3.56466317
train_Precision: 8.33333333, train_Loss: 3.61348915
train_Precision: 0.00000000, train_Loss: 3.89357829
train_Precision: 0.00000000, train_Loss: 3.66159415
train_Precision: 8.33333333, train_Loss: 3.81511998
train_Precision: 0.00000000, train_Loss: 3.75420094
train_Precision: 0.00000000, train_Loss: 3.81874776
train_Precision: 0.00000000, train_Loss: 3.63224411
train_Precision: 25.00000000, train_Loss: 3.49499488
train_Precision: 8.33333333, train_Loss: 3.58996272
train_Precision: 0.00000000, train_Loss: 3.82278943
train_Precision: 0.00000000, train_Loss: 3.84917855
train_Precision: 0.00000000, train_Loss: 3.68733501
train_Precision: 8.33333333, train_Loss: 3.72516155
train_Precision: 8.33333333, train_Loss: 3.74223828
train_Precision: 0.00000000, train_Loss: 3.68328071
train_Precision: 0.00000000, train_Loss: 3.91439509
train_Precision: 8.33333333, train_Loss: 3.91841578
train_Precision: 8.33333333, train_Loss: 3.56331158
train_Precision: 8.33333333, train_Loss: 3.58781219
train_Precision: 8.33333333, train_Loss: 3.55296707
train_Precision: 0.00000000, train_Loss: 3.50027061
train_Precision: 0.00000000, train_Loss: 3.76628804
train_Precision: 0.00000000, train_Loss: 3.52893567
train_Precision: 8.33333333, train_Loss: 3.42603016
train_Precision: 8.33333333, train_Loss: 3.46840596
train_Precision: 0.00000000, train_Loss: 3.51363158
train_Precision: 8.33333333, train_Loss: 3.54374886
train_Precision: 8.33333333, train_Loss: 3.48122287
train_Precision: 8.33333333, train_Loss: 3.54347515
train_Precision: 0.00000000, train_Loss: 3.99474978
train_Precision: 16.66666667, train_Loss: 3.39353371
train_Precision: 8.33333333, train_Loss: 3.41187000
train_Precision: 0.00000000, train_Loss: 3.98592448
train_Precision: 0.00000000, train_Loss: 3.64231300
train_Precision: 0.00000000, train_Loss: 3.88901234
train_Precision: 8.33333333, train_Loss: 3.31839299
train_Precision: 8.33333333, train_Loss: 3.86533856
train_Precision: 8.33333333, train_Loss: 3.61815643
train_Precision: 0.00000000, train_Loss: 3.65574741
train_Precision: 8.33333333, train_Loss: 3.65042901
train_Precision: 8.33333333, train_Loss: 3.38797307
train_Precision: 25.00000000, train_Loss: 3.28482652
train_Precision: 0.00000000, train_Loss: 3.67851472
train_Precision: 0.00000000, train_Loss: 3.76241016
train_Precision: 8.33333333, train_Loss: 3.92465043
train_Precision: 0.00000000, train_Loss: 3.87695694
train_Precision: 0.00000000, train_Loss: 3.66696763
train_Precision: 25.00000000, train_Loss: 3.23287940
train_Precision: 0.00000000, train_Loss: 3.77621484
train_Precision: 8.33333333, train_Loss: 3.33722687
train_Precision: 16.66666667, train_Loss: 3.16274333
